[env]
# =============================================================================
# SSoT: Minimum Thresholds by Asset Class (Issue #62)
# =============================================================================
# These are the canonical values for threshold validation. Change here, affects
# all entry points (Python API + Rust core).
#
# Values are in decimal basis points (dbps): 1000 dbps = 1%
# Research: docs/research/2026-02-03-cfm-optimal-threshold-gemini-3-pro.md
#
# Resolution order (highest priority first):
#   1. Per-symbol: RANGEBAR_MIN_THRESHOLD_<SYMBOL>
#   2. Asset-class: RANGEBAR_<ASSET_CLASS>_MIN_THRESHOLD
#   3. Fallback defaults in code (with warning)

# Crypto: Default minimum (1% - cannot overcome trading costs below this)
# CFM formula validates this as "conservative guardrails"
RANGEBAR_CRYPTO_MIN_THRESHOLD = "1000"

# Forex: Default minimum (tighter spreads allow lower)
RANGEBAR_FOREX_MIN_THRESHOLD = "50"

# Equities: Default minimum
RANGEBAR_EQUITIES_MIN_THRESHOLD = "100"

# Unknown: Fallback (no enforcement)
RANGEBAR_UNKNOWN_MIN_THRESHOLD = "1"

# =============================================================================
# Per-Symbol Overrides (Optional - uncomment to enable)
# =============================================================================
# Override specific symbols when research justifies different thresholds:
#
# RANGEBAR_MIN_THRESHOLD_BTCUSDT = "1500"   # BTC needs higher threshold
# RANGEBAR_MIN_THRESHOLD_XAUUSD = "200"     # Gold needs higher than forex
# RANGEBAR_MIN_THRESHOLD_EURUSD = "25"      # EUR/USD can go lower

# =============================================================================
# GitHub Account Isolation (CRITICAL for multi-account setups)
# =============================================================================
# See: ADR 2025-12-17-github-multi-account-authentication
#
# This ensures all gh CLI and git operations use the correct GitHub identity.
# The git remote MUST use SSH with host alias: git@github.com-terrylica:...
GH_ACCOUNT = "terrylica"
GH_CONFIG_DIR = "{{ env.HOME }}/.config/gh/profiles/terrylica"

# GitHub token for gh CLI operations (uses file-based loading to prevent process storms)
# ADR: 2026-01-15-mise-env-token-loading-patterns.md
# NOTE: For semantic-release, use `mise run release:version` which fetches
# the PAT from Doppler dynamically to avoid stale token issues.
GH_TOKEN = "{{ read_file(path=env.HOME ~ '/.claude/.secrets/gh-token-terrylica') | trim }}"
GITHUB_TOKEN = "{{ read_file(path=env.HOME ~ '/.claude/.secrets/gh-token-terrylica') | trim }}"

# =============================================================================
# 1Password Configuration (SSoT for secrets)
# =============================================================================
# PyPI: op item get djevteztvbcqgcm3yl4njkawjq --fields credential --reveal
# GitHub PAT: stored in gh-token-terrylica file
OP_PYPI_ITEM = "djevteztvbcqgcm3yl4njkawjq"

# =============================================================================
# ClickHouse Cache Configuration (SSoT for cache hosts)
# =============================================================================
# RANGEBAR_CH_HOSTS: SSH aliases for ClickHouse hosts (comma-separated)
# RANGEBAR_CH_PRIMARY: Preferred host when multiple available
# RANGEBAR_MODE: "auto" (default), "local", or "cloud"
#
# AUTO mode: Try localhost first, then SSH tunnel to remote hosts
# LOCAL mode: Only use localhost:8123 (fails if unavailable)
# CLOUD mode: Only use CLICKHOUSE_HOST env var (for cloud deployments)
RANGEBAR_CH_HOSTS = "bigblack"
RANGEBAR_CH_PRIMARY = "bigblack"

# =============================================================================
# Build Configuration
# =============================================================================
BENCH_DATA_DIR = "{{ env.PWD }}/bench-data"
PROFILE_DATA_DIR = "{{ env.PWD }}/profile-data"

# =============================================================================
# Linux Build Configuration
# =============================================================================
# Strategy: Zig cross-compilation (fast, no remote SSH needed)
# Fallback: SSH-based remote Docker build (if zig fails)
LINUX_BUILD_STRATEGY = "zig"  # "zig" or "remote"
LINUX_BUILD_HOST = "bigblack"
LINUX_BUILD_USER = "tca"
LINUX_BUILD_DIR = "/tmp/rangebar-py-build"
LINUX_MATURIN_PROFILE = "wheel"
LINUX_MATURIN_COMPAT = "manylinux_2_17"
LINUX_MIN_DISK_GB = "5"
LINUX_MIN_RUST_VERSION = "1.90"

# Build lock directory (prevents stale processes)
BUILD_LOCK_DIR = "/tmp/rangebar-py-locks"

# =============================================================================
# Tools - managed by mise (NOT separate cargo install)
# =============================================================================

[tools]
python = "3.13"
rust = "1.90"
node = "22"          # Required for semantic-release
uv = "latest"        # Required for publish workflow
zig = "0.13"         # Cross-compilation toolchain (maturin --zig)
# Cargo tools installed as mise plugins
"cargo:cargo-nextest" = "latest"
"cargo:cargo-deny" = "latest"
"cargo:cargo-outdated" = "latest"
"cargo:flamegraph" = "0.6"
"cargo:maturin" = "latest"

# =============================================================================
# Development Tasks (from Makefile)
# =============================================================================

[tasks.fmt]
description = "Format code with cargo fmt"
run = "cargo fmt --all"

[tasks.lint]
description = "Run clippy linting"
run = "cargo clippy --all-targets --all-features"

[tasks.test]
description = "Run Rust tests with cargo nextest (excludes PyO3 root crate)"
run = "cargo nextest run --workspace --exclude rangebar-py"

[tasks.test-py]
description = "Run Python tests"
run = "pytest tests/ -v"

[tasks."test:e2e"]
description = "Run end-to-end tests (requires ClickHouse)"
run = "pytest tests/ -v -m 'not slow' --tb=short"

[tasks."test:clickhouse"]
description = "Run ClickHouse-specific tests"
run = "pytest tests/ -v -m clickhouse --tb=short"

[tasks."test:all"]
description = "Run all tests including slow and ClickHouse"
run = "pytest tests/ -v --tb=short"

[tasks.deny]
description = "Run cargo deny security checks"
run = "cargo deny check"

[tasks.check]
description = "Run all quality checks (fmt + test)"
depends = ["fmt", "test"]

[tasks.check-full]
description = "Full quality checks including lint and deny"
depends = ["fmt", "lint", "test", "deny"]

[tasks.build]
description = "Build Python extension (development)"
run = "maturin develop"

[tasks.build-release]
description = "Build in release mode"
run = "cargo build --release"

[tasks.clean]
description = "Clean build artifacts"
run = "cargo clean && rm -rf dist/ build/ *.egg-info"

[tasks.docs]
description = "Generate documentation"
run = "cargo doc --open --all-features"

[tasks.dev]
description = "Quick development cycle (fmt + test)"
depends = ["fmt", "test"]

# =============================================================================
# Benchmarking Tasks (REPLACES benchmark_runner.sh)
# =============================================================================

[tasks."bench:run"]
description = "Run performance benchmarks"
run = "cargo bench --bench rangebar_bench"

[tasks."bench:quick"]
description = "Run quick benchmarks (reduced iterations)"
run = "cargo bench --bench rangebar_bench -- --quick"

[tasks."bench:baseline"]
description = "Create performance baseline"
run = """
mkdir -p $BENCH_DATA_DIR
cargo bench --bench rangebar_bench -- --save-baseline main
echo "Baseline saved to $BENCH_DATA_DIR/main"
"""

[tasks."bench:compare"]
description = "Compare current performance with baseline"
run = "cargo bench --bench rangebar_bench -- --baseline main"

[tasks."bench:validate"]
description = "Validate performance targets (1M ticks < 100ms)"
run = """
echo "Running performance validation..."
cargo bench --bench rangebar_bench -- --quick 2>&1 | tee /tmp/bench_output.txt
if grep -q "1M.*time:.*[0-9][0-9][0-9]\\.[0-9]* ms" /tmp/bench_output.txt; then
  echo "FAIL: 1M ticks benchmark exceeds 100ms target"
  exit 1
fi
echo "PASS: Performance targets met"
"""

# =============================================================================
# Profiling Tasks (REPLACES profiling_tools.sh for simple cases)
# =============================================================================

[tasks."prof:flamegraph"]
description = "Generate CPU flamegraph"
run = """
mkdir -p $PROFILE_DATA_DIR
cargo flamegraph --bench rangebar_bench -o $PROFILE_DATA_DIR/flamegraph-$(date +%Y%m%d-%H%M%S).svg
echo "Flamegraph saved to $PROFILE_DATA_DIR/"
"""

[tasks."prof:build-release"]
description = "Build with profiling symbols"
run = "CARGO_PROFILE_RELEASE_DEBUG=true cargo build --release"

# Complex profiling (platform-specific) kept in script
[tasks."prof:full"]
description = "Comprehensive profiling suite (uses script for platform detection)"
run = "./scripts/profiling_tools.sh full"

# =============================================================================
# Dependency Management Tasks (PARTIAL - complex logic in script)
# =============================================================================

[tasks."deps:check"]
description = "Check for outdated dependencies"
run = "cargo outdated -R --color always"

[tasks."deps:security"]
description = "Run security audit on dependencies"
run = "cargo deny check advisories && cargo deny check licenses"

[tasks."deps:tree"]
description = "Show dependency tree (depth 1)"
run = "cargo tree --depth 1 | grep -E '^[a-z]'"

[tasks."deps:update"]
description = "Update dependencies (simple - no rollback)"
run = """
cargo update
cargo nextest run --no-fail-fast
echo "Dependencies updated and tests passed"
"""

# Complex update with rollback kept in script
[tasks."deps:update-safe"]
description = "Update dependencies with backup/rollback (uses script)"
run = "./scripts/dependency_monitor.sh auto"

# =============================================================================
# Production Validation Tasks (REPLACES production_validation.sh)
# =============================================================================

[tasks."validate:security"]
description = "Validate no privilege escalation in scripts"
run = """
if grep -r 'sudo' scripts/*.sh 2>/dev/null; then
  echo "FAIL: Found sudo usage in scripts"
  exit 1
fi
echo "PASS: No privilege escalation detected"
"""

[tasks."validate:injection"]
description = "Validate command injection prevention"
run = """
if grep -E '\\$\\(.*\\$[A-Z]' scripts/*.sh 2>/dev/null; then
  echo "WARN: Potential command injection pattern found"
fi
echo "PASS: Command injection check complete"
"""

[tasks."validate:memory"]
description = "Validate memory efficiency for high-volume months (prevents OOM regressions)"
run = "python scripts/validate_memory_efficiency.py"

[tasks."validate:all"]
description = "Run all production validation checks"
depends = ["validate:security", "validate:injection", "validate:memory"]

[tasks."validate:clickhouse"]
description = "Validate ClickHouse connectivity and cache integrity"
run = "python scripts/validate_clickhouse.py"

# =============================================================================
# ClickHouse Cache Tasks
# =============================================================================

[tasks."cache:status"]
description = "Show ClickHouse cache statistics"
run = "python scripts/cache_status.py"

[tasks."cache:clear"]
description = "Clear ClickHouse cache for a symbol (interactive)"
run = "python scripts/cache_clear.py"

# =============================================================================
# Release Tasks
# =============================================================================

[tasks.release]
description = "Build all release wheels"
run = "./scripts/build-release.sh"

[tasks.publish]
description = "Publish wheels to PyPI"
run = "./scripts/publish-wheels.sh"

[tasks."release:local"]
description = "Build local wheel only (macOS ARM64)"
run = "maturin build --profile wheel"

[tasks."release:sdist"]
description = "Build source distribution"
run = "maturin sdist"

# =============================================================================
# Platform-Specific Build Tasks (Issue #17)
# =============================================================================

[tasks."release:macos-arm64"]
description = "Build macOS ARM64 wheels for Python 3.13 (native)"
run = """
echo "=== Building macOS ARM64 wheels (Python 3.13) ==="
for pyver in python3.13; do
    if command -v $pyver &> /dev/null; then
        echo "Building for $pyver..."
        maturin build --profile wheel -i $pyver
    else
        echo "WARN: $pyver not found, skipping"
    fi
done
echo "OK: macOS ARM64 wheels built"
"""

[tasks."release:linux-preflight"]
description = "Verify Linux build prerequisites (zig or remote host)"
run = """
#!/usr/bin/env bash
set -euo pipefail

echo "=== Linux Build Preflight ==="

# Ensure lock directory exists
mkdir -p "$BUILD_LOCK_DIR"

# Check for stale locks (older than 30 minutes)
find "$BUILD_LOCK_DIR" -name "*.lock" -mmin +30 -delete 2>/dev/null || true
find "$BUILD_LOCK_DIR" -name "*.lock.d" -type d -mmin +30 -exec rm -rf {} + 2>/dev/null || true

# Check zig availability (primary strategy)
if command -v zig &>/dev/null; then
    ZIG_VERSION=$(zig version)
    echo "OK: Zig available: $ZIG_VERSION"
else
    echo "WARN: Zig not found - will use remote Docker fallback"
fi

# Check rustup target
if rustup target list --installed | grep -q x86_64-unknown-linux-gnu; then
    echo "OK: Linux target installed"
else
    echo "INFO: Installing Linux target..."
    rustup target add x86_64-unknown-linux-gnu
    echo "OK: Linux target installed"
fi

# Verify .cargo/config.toml exists (prevents target-cpu=native errors)
if [ -f ".cargo/config.toml" ]; then
    echo "OK: .cargo/config.toml exists"
else
    echo "WARN: .cargo/config.toml missing - cross-compile may fail"
    echo "      Create it with cross-compile friendly rustflags"
fi

# Fallback: check remote host if zig strategy fails
if [ "${LINUX_BUILD_STRATEGY:-zig}" = "remote" ]; then
    if ! ssh -o ConnectTimeout=5 -o BatchMode=yes "$LINUX_BUILD_USER@$LINUX_BUILD_HOST" "echo connected" >/dev/null 2>&1; then
        echo "FAIL: Cannot connect to $LINUX_BUILD_USER@$LINUX_BUILD_HOST"
        exit 1
    fi
    echo "OK: SSH connectivity verified (remote fallback ready)"
fi

echo "OK: Preflight passed"
"""

[tasks."release:linux"]
description = "Build Linux x86_64 wheels (zig cross-compile, no remote needed)"
depends = ["release:linux-preflight"]
run = """
#!/usr/bin/env bash
set -euo pipefail

echo "=== Building Linux x86_64 Wheels ==="

# Acquire exclusive build lock (cross-platform: macOS + Linux)
LOCK_FILE="$BUILD_LOCK_DIR/release-linux.lock"

# Check for stale lock (older than 10 minutes)
if [ -f "$LOCK_FILE" ]; then
    LOCK_AGE=$(($(date +%s) - $(stat -f %m "$LOCK_FILE" 2>/dev/null || stat -c %Y "$LOCK_FILE" 2>/dev/null || echo 0)))
    if [ "$LOCK_AGE" -gt 600 ]; then
        echo "WARN: Removing stale lock (age: ${LOCK_AGE}s)"
        rm -f "$LOCK_FILE"
    fi
fi

# Atomic lock acquisition using mkdir (works on both macOS and Linux)
LOCK_DIR="${LOCK_FILE}.d"
if ! mkdir "$LOCK_DIR" 2>/dev/null; then
    echo "FAIL: Another Linux build is running"
    echo "Lock holder PID: $(cat "$LOCK_FILE" 2>/dev/null || echo 'unknown')"
    echo "To force: rm -rf $LOCK_DIR $LOCK_FILE"
    exit 1
fi
echo "$$" > "$LOCK_FILE"
echo "OK: Acquired build lock"

cleanup() {
    rm -rf "$LOCK_DIR" "$LOCK_FILE"
    echo "Released build lock"
}
trap cleanup EXIT

# Strategy: Zig cross-compilation (fast, ~1 min)
if [ "${LINUX_BUILD_STRATEGY:-zig}" = "zig" ]; then
    echo "Strategy: Zig cross-compilation"

    # CRITICAL: Clear RUSTFLAGS to avoid target-cpu=native breaking cross-compile
    # The ~/.cargo/config.toml may have target-specific flags, but RUSTFLAGS env
    # takes precedence and can contain incompatible options like -C target-cpu=native
    export RUSTFLAGS=""
    export RUSTC_WRAPPER=""  # Disable sccache for cross-compile (cache pollution)

    # Build with zig linker
    maturin build --release \
        --target x86_64-unknown-linux-gnu \
        --zig \
        --compatibility manylinux_2_17 \
        -i python3.13

    # Copy latest wheel to dist/
    mkdir -p dist/
    WHEEL=$(ls -t target/wheels/*manylinux*.whl | head -1)
    cp "$WHEEL" dist/
    echo "OK: Linux wheels built via zig"
    ls -la "$WHEEL"
    exit 0
fi

# Fallback: Remote Docker build (slow, ~5 min)
echo "Strategy: Remote Docker build (fallback)"
PROJECT_DIR="$(pwd)"
REMOTE_DIR="${LINUX_BUILD_DIR}-$$"

remote_cleanup() {
    ssh "$LINUX_BUILD_USER@$LINUX_BUILD_HOST" "rm -rf $REMOTE_DIR" 2>/dev/null || true
    rm -f "$LOCK_FILE"
}
trap remote_cleanup EXIT

ssh "$LINUX_BUILD_USER@$LINUX_BUILD_HOST" "mkdir -p $REMOTE_DIR"

rsync -az --delete \
    --exclude 'target/' --exclude 'dist/' --exclude '.git/' \
    --exclude '__pycache__/' --exclude '*.egg-info/' --exclude 'node_modules/' \
    "$PROJECT_DIR/" "$LINUX_BUILD_USER@$LINUX_BUILD_HOST:$REMOTE_DIR/"

# Build using manylinux Docker container (rustls = no openssl needed)
ssh "$LINUX_BUILD_USER@$LINUX_BUILD_HOST" 'cd '"$REMOTE_DIR"' && docker run --rm -v $(pwd):/io -w /io quay.io/pypa/manylinux2014_x86_64 bash -c "curl --proto =https --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y && source ~/.cargo/env && /opt/python/cp313-cp313/bin/pip install maturin && /opt/python/cp313-cp313/bin/maturin build --profile wheel --compatibility manylinux2014 -i /opt/python/cp313-cp313/bin/python"'

mkdir -p dist/
scp "$LINUX_BUILD_USER@$LINUX_BUILD_HOST:$REMOTE_DIR/target/wheels/*manylinux*.whl" dist/
echo "OK: Linux wheels built via remote Docker (~5 min)"
"""

# =============================================================================
# 4-Phase Workflow Tasks
# =============================================================================

[tasks."release:preflight"]
description = "Validate release prerequisites (Phase 1)"
run = """
#!/usr/bin/env bash
set -euo pipefail

echo "=== PREFLIGHT ==="
git update-index --refresh -q || true

if [ -n "$(git status --porcelain)" ]; then
    echo "FAIL: Working directory not clean"
    git status --short
    exit 1
fi

BRANCH=$(git branch --show-current)
if [ "$BRANCH" != "main" ]; then
    echo "FAIL: Not on main branch (on: $BRANCH)"
    exit 1
fi

# Clean dist/ to prevent stale wheel accumulation
if [ -d dist ]; then
    echo "Cleaning dist/ directory..."
    rm -rf dist
fi
mkdir -p dist

echo "OK: Preflight passed"
"""

[tasks."release:sync"]
description = "Synchronize with remote (Phase 2) - SSH with port fallback"
depends = ["release:preflight"]
run = """
#!/usr/bin/env bash
set -euo pipefail

echo "=== SYNC ==="

# Git SSH with automatic port fallback (443 â†’ 22)
# Port 443 is configured in ~/.ssh/config but can timeout on some networks
git_ssh_with_fallback() {
    local cmd="$1"

    # Try default SSH config first (uses port 443 via ssh.github.com)
    if timeout 15 git $cmd 2>/dev/null; then
        return 0
    fi

    echo "WARN: Default SSH timed out, falling back to port 22..."

    # Fallback: Direct port 22 connection
    export GIT_SSH_COMMAND='ssh -p 22 -i ~/.ssh/id_ed25519_terrylica -o IdentitiesOnly=yes -o ConnectTimeout=10'
    git $cmd
}

# Ensure remote URL uses SSH with host alias
REMOTE_URL=$(git remote get-url origin)
if [[ ! "$REMOTE_URL" =~ github.com-terrylica ]]; then
    echo "Fixing remote URL for terrylica identity..."
    git remote set-url origin "git@github.com-terrylica:terrylica/rangebar-py.git"
fi

# Sync with fallback
git_ssh_with_fallback "pull --rebase origin main" || { echo "FAIL: Pull failed"; exit 1; }
git_ssh_with_fallback "push origin main" || { echo "FAIL: Push failed"; exit 1; }

# Unset to avoid polluting subsequent commands
unset GIT_SSH_COMMAND

echo "OK: Synced"
"""

[tasks."release:check-config"]
description = "Verify release configuration (GitHub, Doppler, SSH)"
run = "./scripts/check-release-config.sh"

[tasks."release:build-all"]
description = "Build all platform wheels + sdist (Phase 3 - runs AFTER version bump)"
depends = ["release:version"]
run = """
#!/usr/bin/env bash
set -euo pipefail

echo "=== BUILD ALL PLATFORMS ==="

# Get version from Cargo.toml (SSoT)
VERSION=$(grep -A5 '\\[workspace.package\\]' Cargo.toml | grep '^version' | head -1 | sed 's/.*= "\\(.*\\)"/\\1/')
echo "Building version: $VERSION"

# Check if this version already exists on PyPI (prevents wasted build time)
echo "Checking PyPI for existing version..."
if pip index versions rangebar 2>/dev/null | grep -q "^rangebar ($VERSION)$"; then
    echo "WARN: Version $VERSION already exists on PyPI"
    echo "INFO: semantic-release found no releasable commits (feat:/fix:)"
    echo "INFO: The 'build:' commit type does not trigger version bumps"
    echo ""
    echo "To force a release, make a feat: or fix: commit, or:"
    echo "  1. Manually bump version in Cargo.toml"
    echo "  2. Run: mise run release:build-only"
    exit 0
fi

# Build all platforms
mise run release:macos-arm64
mise run release:linux
mise run release:sdist

# Copy to dist/ (Linux wheel already lands there)
cp -n target/wheels/rangebar-${VERSION}-*.whl dist/ 2>/dev/null || true
cp -n target/wheels/rangebar-${VERSION}.tar.gz dist/ 2>/dev/null || true

echo ""
echo "OK: All wheels + sdist built for v$VERSION"
ls -la dist/rangebar-${VERSION}* 2>/dev/null || true
"""

[tasks."release:build-only"]
description = "Build wheels WITHOUT version check (for manual releases)"
run = """
#!/usr/bin/env bash
set -euo pipefail

echo "=== BUILD ONLY (no version check) ==="

VERSION=$(grep -A5 '\\[workspace.package\\]' Cargo.toml | grep '^version' | head -1 | sed 's/.*= "\\(.*\\)"/\\1/')
echo "Building version: $VERSION"

# Clean dist/
rm -rf dist && mkdir -p dist

mise run release:macos-arm64
mise run release:linux
mise run release:sdist

cp -n target/wheels/rangebar-${VERSION}-*.whl dist/ 2>/dev/null || true
cp -n target/wheels/rangebar-${VERSION}.tar.gz dist/ 2>/dev/null || true

echo ""
echo "OK: Wheels built"
ls -la dist/rangebar-${VERSION}* 2>/dev/null || true
"""

[tasks."release:postflight"]
description = "Verify and publish (Phase 4 - runs AFTER builds)"
depends = ["smoke", "release:build-all"]
run = """
echo "=== POSTFLIGHT ==="
WHEEL_COUNT=$(find dist/ -name "*.whl" 2>/dev/null | wc -l | tr -d ' ')
echo "Found $WHEEL_COUNT wheel(s)"
ls -la dist/*.whl 2>/dev/null || true
echo ""
echo "To publish: mise run publish"
"""

[tasks."release:version"]
description = "Bump version via semantic-release with Doppler GitHub token"
depends = ["release:sync"]
run = "./scripts/semantic-release.sh"

[tasks."release:dry"]
description = "Preview what semantic-release would do (no changes)"
run = "bun install --silent 2>/dev/null && GH_CONFIG_DIR=$HOME/.config/gh/profiles/terrylica GITHUB_TOKEN=$(gh auth token) bun run semantic-release --dry-run --no-ci"

[tasks."release:pypi"]
description = "Publish to PyPI using 1Password credentials (local-only, ADR-0027)"
depends = ["release:build-all"]
run = "./scripts/publish-to-pypi.sh"

[tasks."release:full"]
description = "Full release workflow: version bump â†’ build â†’ smoke â†’ publish to PyPI"
# Dependency chain enforced via task-level depends:
#   preflight â†’ sync â†’ version â†’ build-all â†’ postflight
#                                    â†“
#                              release:pypi (publish)
# mise resolves the full DAG automatically.
depends = ["release:postflight", "release:pypi"]
run = """
#!/usr/bin/env bash
set -euo pipefail

VERSION=$(grep -A5 '\\[workspace.package\\]' Cargo.toml | grep '^version' | head -1 | sed 's/.*= "\\(.*\\)"/\\1/')

echo '========================================='
echo " Release v$VERSION complete!"
echo '========================================='
echo ""
echo "Published to PyPI: https://pypi.org/project/rangebar/$VERSION/"
echo ""
echo "Wheels:"
ls dist/rangebar-${VERSION}*.whl 2>/dev/null || echo "  (none in dist/)"
"""

[tasks."release:quick"]
description = "Quick release: build + publish (skips sync, for when GitHub is unreachable)"
depends = ["release:preflight", "smoke"]
run = """
#!/usr/bin/env bash
set -euo pipefail

echo "=== QUICK RELEASE (no sync) ==="
echo "WARN: Skipping GitHub sync - ensure you're up to date manually"

VERSION=$(grep -A5 '\\[workspace.package\\]' Cargo.toml | grep '^version' | head -1 | sed 's/.*= "\\(.*\\)"/\\1/')
echo "Version: $VERSION"

# Check PyPI
if pip index versions rangebar 2>/dev/null | grep -q "^rangebar ($VERSION)$"; then
    echo "FAIL: Version $VERSION already on PyPI"
    echo "Bump version in Cargo.toml first"
    exit 1
fi

# Build
mise run release:build-only

# Publish
mise run publish

echo ""
echo "OK: v$VERSION published to PyPI"
"""

# =============================================================================
# Smoke Test Tasks
# =============================================================================

[tasks."smoke:import"]
description = "Verify Python import works"
run = "python -c 'from rangebar import RangeBarProcessor; print(\"OK: import works\")'"

[tasks."smoke:process"]
description = "Verify basic processing works"
run = """
python -c '
from rangebar._core import PyRangeBarProcessor
proc = PyRangeBarProcessor(threshold_decimal_bps=250)
assert proc.threshold_decimal_bps == 250
bars = proc.process_trades([])
assert bars == []
print("OK: basic processing works")
'
"""

[tasks.smoke]
description = "Run all smoke tests"
depends = ["smoke:import", "smoke:process"]

# =============================================================================
# Checksum Verification Tasks (Issue #43)
# =============================================================================

[tasks."test:checksum"]
description = "Test Rust checksum verification module"
run = "cargo nextest run -p rangebar-providers checksum"

[tasks."test:checksum:integration"]
description = "Integration test with real Binance data (requires network)"
run = """
python -c '
from rangebar import get_range_bars
import logging
logging.basicConfig(level=logging.DEBUG)

# Test with checksum verification (should see checksum events in logs)
df = get_range_bars("BTCUSDT", "2024-01-01", "2024-01-01", verify_checksum=True)
print(f"Downloaded {len(df)} bars with checksum verification")
'
"""

[tasks."checksum:audit"]
description = "Audit Tier 1 cache for unverified files"
run = """
python -c '
from rangebar.storage.checksum_registry import ChecksumRegistry
registry = ChecksumRegistry()
count = registry.get_verified_count("BTCUSDT")
print(f"BTCUSDT verified dates: {count}")
'
"""

[tasks."checksum:pushover-test"]
description = "Send test Pushover alert to verify credentials"
run = """
python -c '
from rangebar.notify.pushover import send_critical_alert
result = send_critical_alert(
    title="ðŸ§ª RB Test Alert",
    message="Checksum verification test - ignore this alert.",
)
print(f"Pushover alert sent: {result}")
'
"""

# =============================================================================
# Research Cache Population Tasks (Issue #58)
# =============================================================================
# Sequential execution to avoid OOM on limited-memory hosts
# Run on littleblack: ssh littleblack "cd /home/kab/eon/rangebar-py && mise run research:populate-250"

[tasks."research:populate-symbol"]
description = "Populate cache for a single symbol (requires SYMBOL and THRESHOLD env vars)"
run = """
#!/usr/bin/env bash
set -e

# Use uv to run in the project venv
uv run --python 3.13 python -c '
import os
import sys
import time
from datetime import UTC, datetime, timedelta

from rangebar import get_range_bars

SYMBOL = os.environ.get("SYMBOL")
if not SYMBOL:
    print("ERROR: SYMBOL env var required", flush=True)
    sys.exit(1)

START = os.environ.get("START", "2022-01-01")
END = os.environ.get("END", "2025-12-31")
THRESHOLD = int(os.environ.get("THRESHOLD", "250"))

def date_range_months(start_str, end_str):
    start = datetime.strptime(start_str, "%Y-%m-%d").replace(tzinfo=UTC)
    end = datetime.strptime(end_str, "%Y-%m-%d").replace(tzinfo=UTC)
    current = start
    while current < end:
        month_end = (current.replace(day=28) + timedelta(days=4)).replace(day=1) - timedelta(days=1)
        month_end = min(month_end, end)
        yield current.strftime("%Y-%m-%d"), month_end.strftime("%Y-%m-%d")
        current = month_end + timedelta(days=1)

print(f"Populating {SYMBOL} @ {THRESHOLD} dbps ({START} to {END})", flush=True)
total_bars = 0
for chunk_start, chunk_end in date_range_months(START, END):
    t0 = time.time()
    try:
        df = get_range_bars(SYMBOL, chunk_start, chunk_end, threshold_decimal_bps=THRESHOLD, use_cache=True, fetch_if_missing=True)
        elapsed = time.time() - t0
        total_bars += len(df)
        print(f"  {chunk_start}: {len(df):>6,} bars ({elapsed:>5.1f}s)", flush=True)
    except Exception as e:
        print(f"  {chunk_start}: ERROR - {e}", flush=True)
print(f"DONE: {total_bars:,} total bars", flush=True)
'
"""

[tasks."research:populate-all"]
description = "Populate cache for all symbols at 250 then 1000 dbps (fully sequential)"
run = """
#!/usr/bin/env bash
set -e

echo "=========================================="
echo "FULL CACHE POPULATION - 250 dbps then 1000 dbps"
echo "=========================================="
echo "Started: $(date)"

# Run 250 dbps first (all symbols)
mise run research:populate-250

# Then run 1000 dbps (all symbols)
mise run research:populate-1000

echo ""
echo "=========================================="
echo "ALL POPULATION COMPLETE (250 + 1000 dbps)"
echo "Finished: $(date)"
echo "=========================================="
"""

[tasks."research:populate-250"]
description = "Populate 250 dbps cache for all symbols (sequential, OOM-safe)"
run = """
#!/usr/bin/env bash
set -e

echo "=== SEQUENTIAL CACHE POPULATION (250 dbps) ==="
echo "Running symbols one at a time to avoid OOM..."
echo "Started: $(date)"

SYMBOLS="BTCUSDT ETHUSDT BNBUSDT ADAUSDT AVAXUSDT DOTUSDT MATICUSDT NEARUSDT ATOMUSDT APTUSDT SUIUSDT LINKUSDT UNIUSDT AAVEUSDT DOGEUSDT SHIBUSDT PEPEUSDT FTMUSDT"

TOTAL=18
CURRENT=0

for SYMBOL in $SYMBOLS; do
    CURRENT=$((CURRENT + 1))
    echo ""
    echo "=========================================="
    echo "[$CURRENT/$TOTAL] $SYMBOL @ 250 dbps"
    echo "=========================================="
    SYMBOL=$SYMBOL THRESHOLD=250 mise run research:populate-symbol
    echo "Completed $SYMBOL. Sleeping 10s before next..."
    sleep 10
done

echo ""
echo "=========================================="
echo "ALL $TOTAL SYMBOLS @ 250 dbps COMPLETE"
echo "Finished: $(date)"
echo "=========================================="
"""

[tasks."research:populate-1000"]
description = "Populate 1000 dbps cache for all symbols (sequential, OOM-safe)"
run = """
#!/usr/bin/env bash
set -e

echo "=== SEQUENTIAL CACHE POPULATION (1000 dbps) ==="
echo "Running symbols one at a time to avoid OOM..."
echo "Started: $(date)"

SYMBOLS="BTCUSDT ETHUSDT BNBUSDT ADAUSDT AVAXUSDT DOTUSDT MATICUSDT NEARUSDT ATOMUSDT APTUSDT SUIUSDT LINKUSDT UNIUSDT AAVEUSDT DOGEUSDT SHIBUSDT PEPEUSDT FTMUSDT"

TOTAL=18
CURRENT=0

for SYMBOL in $SYMBOLS; do
    CURRENT=$((CURRENT + 1))
    echo ""
    echo "=========================================="
    echo "[$CURRENT/$TOTAL] $SYMBOL @ 1000 dbps"
    echo "=========================================="
    SYMBOL=$SYMBOL THRESHOLD=1000 mise run research:populate-symbol
    echo "Completed $SYMBOL. Sleeping 10s before next..."
    sleep 10
done

echo ""
echo "=========================================="
echo "ALL $TOTAL SYMBOLS @ 1000 dbps COMPLETE"
echo "Finished: $(date)"
echo "=========================================="
"""

[tasks."research:status"]
description = "Check population status on littleblack (single check)"
run = "python scripts/monitor_population.py --once --host littleblack"

[tasks."research:monitor"]
description = "Start continuous population monitoring (2 min interval)"
run = "python scripts/monitor_population.py --interval 120 --host littleblack"

[tasks."research:momentum-analysis"]
description = "Run momentum analysis on all populated symbols"
run = "python scripts/run_length_momentum_multi_symbol.py"

[tasks."research:wfo-analysis"]
description = "Run Walk-Forward regime detection"
run = "python scripts/run_length_momentum_wfo.py"

# =============================================================================
# Diagnostics Tasks
# =============================================================================

[tasks."diag:release"]
description = "Diagnose release environment (SSH, tools, PyPI)"
run = """
#!/usr/bin/env bash
set -euo pipefail

echo "=== RELEASE DIAGNOSTICS ==="
echo ""

# Version info
VERSION=$(grep -A5 '\\[workspace.package\\]' Cargo.toml | grep '^version' | head -1 | sed 's/.*= "\\(.*\\)"/\\1/')
echo "Local version: $VERSION"

# PyPI check
echo ""
echo "--- PyPI Status ---"
PYPI_VERSION=$(pip index versions rangebar 2>/dev/null | head -1 | sed 's/rangebar (\\(.*\\))/\\1/' || echo "unknown")
echo "PyPI latest: $PYPI_VERSION"
if [ "$VERSION" = "$PYPI_VERSION" ]; then
    echo "STATUS: Version $VERSION already on PyPI"
else
    echo "STATUS: Version $VERSION NOT on PyPI (publishable)"
fi

# Git status
echo ""
echo "--- Git Status ---"
echo "Branch: $(git branch --show-current)"
echo "Clean: $(git status --porcelain | wc -l | tr -d ' ') uncommitted files"
echo "Remote: $(git remote get-url origin)"

# SSH connectivity
echo ""
echo "--- SSH Connectivity ---"
echo -n "Port 443 (ssh.github.com): "
SSH_OUT=$(timeout 15 ssh -T -o ConnectTimeout=10 git@github.com-terrylica 2>&1 || true)
if echo "$SSH_OUT" | grep -q "successfully authenticated"; then
    echo "OK"
elif echo "$SSH_OUT" | grep -qi "timeout\\|timed out"; then
    echo "TIMEOUT"
else
    echo "FAIL"
fi

echo -n "Port 22 (direct): "
SSH_OUT=$(timeout 20 ssh -T -p 22 -i ~/.ssh/id_ed25519_terrylica -o IdentitiesOnly=yes -o ConnectTimeout=15 git@github.com 2>&1 || true)
if echo "$SSH_OUT" | grep -q "successfully authenticated"; then
    echo "OK"
elif echo "$SSH_OUT" | grep -qi "timeout\\|timed out"; then
    echo "TIMEOUT"
else
    echo "FAIL"
fi

# Tools
echo ""
echo "--- Build Tools ---"
echo "Rust: $(rustc --version 2>/dev/null || echo 'not found')"
echo "Zig: $(zig version 2>/dev/null || echo 'not found')"
echo "Maturin: $(maturin --version 2>/dev/null || echo 'not found')"
echo "Linux target: $(rustup target list --installed | grep -q x86_64-unknown-linux-gnu && echo 'installed' || echo 'missing')"

# Cargo config
echo ""
echo "--- Cargo Config ---"
if [ -f ".cargo/config.toml" ]; then
    echo "Project .cargo/config.toml: exists"
    # Check if target-cpu=native is in [build] section (bad) vs target-specific (ok)
    # Only check non-comment lines (rustflags = [...])
    if grep -A5 "^\\[build\\]" .cargo/config.toml | grep "^rustflags" | grep -q "target-cpu=native"; then
        echo "  WARN: [build] section has target-cpu=native (breaks cross-compile)"
    elif grep "^rustflags" .cargo/config.toml | grep -q "target-cpu=native"; then
        echo "  OK: target-cpu=native only in target-specific sections"
    else
        echo "  OK: No target-cpu=native in rustflags"
    fi
else
    echo "Project .cargo/config.toml: MISSING (may need for cross-compile)"
fi

# Build locks
echo ""
echo "--- Build Locks ---"
if [ -d "$BUILD_LOCK_DIR" ]; then
    LOCKS=$(find "$BUILD_LOCK_DIR" -name "*.lock*" 2>/dev/null | wc -l | tr -d ' ')
    echo "Lock directory: $BUILD_LOCK_DIR"
    echo "Active locks: $LOCKS"
    ls -la "$BUILD_LOCK_DIR"/*.lock* 2>/dev/null || echo "  (none)"
else
    echo "Lock directory: not created yet"
fi

# 1Password
echo ""
echo "--- Credentials ---"
echo -n "1Password PyPI token: "
if op item get djevteztvbcqgcm3yl4njkawjq --fields credential --reveal 2>/dev/null | head -c 10 >/dev/null; then
    echo "accessible"
else
    echo "FAIL (run: op signin)"
fi

echo ""
echo "=== END DIAGNOSTICS ==="
"""

[tasks."diag:locks-clear"]
description = "Clear all build locks (use when stuck)"
run = """
#!/usr/bin/env bash
echo "Clearing build locks..."
rm -rf "$BUILD_LOCK_DIR"/*.lock* 2>/dev/null || true
rm -rf "$BUILD_LOCK_DIR"/*.lock.d 2>/dev/null || true
echo "OK: Locks cleared"
ls -la "$BUILD_LOCK_DIR" 2>/dev/null || echo "Lock directory empty"
"""

[tasks."diag:ssh-fix"]
description = "Test and fix SSH connectivity to GitHub"
run = """
#!/usr/bin/env bash
set -euo pipefail

echo "=== SSH Connectivity Fix ==="

# Test port 443 (configured in ~/.ssh/config)
echo -n "Testing port 443 (ssh.github.com)... "
if timeout 15 ssh -T -o ConnectTimeout=10 git@github.com-terrylica 2>&1 | grep -q "successfully authenticated"; then
    echo "OK"
    echo "Port 443 works - no fix needed"
    exit 0
else
    echo "TIMEOUT"
fi

# Test port 22 (direct)
echo -n "Testing port 22 (github.com direct)... "
if timeout 20 ssh -T -p 22 -i ~/.ssh/id_ed25519_terrylica -o IdentitiesOnly=yes -o ConnectTimeout=15 git@github.com 2>&1 | grep -q "successfully authenticated"; then
    echo "OK"
    echo ""
    echo "Port 22 works but port 443 doesn't."
    echo "Your network may be blocking port 443 to ssh.github.com"
    echo ""
    echo "Options:"
    echo "  1. Update ~/.ssh/config to use port 22:"
    echo "     Host github.com-terrylica"
    echo "         HostName github.com"
    echo "         Port 22"
    echo "         User git"
    echo "         IdentityFile ~/.ssh/id_ed25519_terrylica"
    echo ""
    echo "  2. Use mise run release:quick (skips sync)"
    echo ""
    echo "  3. Manually sync with:"
    echo "     GIT_SSH_COMMAND='ssh -p 22 -i ~/.ssh/id_ed25519_terrylica' git pull --rebase origin main"
else
    echo "FAIL"
    echo ""
    echo "Both ports failing - check:"
    echo "  1. SSH key exists: ls -la ~/.ssh/id_ed25519_terrylica"
    echo "  2. Key added to GitHub: gh ssh-key list"
    echo "  3. Network connectivity: ping github.com"
fi
"""
